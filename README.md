# Speech Emotion Recognition
This was a group project for ST456 - Deep Learning at LSE. I worked in collaboration with Michele Bergami, Elisabetta Sanasi and Lucy Malabar.

This projected explores the realm of speech emotion recognition (SER), investigating the influence of data augmentation, model architectures, 
and dataset characteristics on classification accuracy. Our study introduces CNN and parallel CNN-RNN models for SER, examining their performance 
across various datasets and augmentation techniques. Our results demonstrate that data augmentation techniques, particularly pitch manipulation, 
significantly improve classification accuracy, particularly within the CNN framework. Also, we used Grad-CAM to provide insights into the modelsâ€™ 
decision-making processes, revealing patterns in audio features associated with different emotions. Finally, we investigated the impact of gender 
bias and emotion intensity on model performance, revealing that models are more accurate under conditions of stronger emotino intensity and when 
the speaker is female.

My technical contribution was mainly on the literary review and the general outline of the project. 
In addition, in collaboration of my groupmates, I researched the appropriate datasets, I worked on the interpretation of the Grad-CAM results, on the 
implementation of the models and I curated the final report.
